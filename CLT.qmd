---
title: "The Effects of Skewness on the Central Limit Theorem"
author: "Visruth Srimath Kandali, Beth Chance, California Polytechnic San Luis Obispo Department of Statistics"
format: html
embed-resources: true
# engine: julia # min Quarto 1.5
---

## Creating the Data

```{julia sampling distribution}
#| output: false
using Distributions, Random, DataFrames, CSV, StatsBase

function standardize(x, μ, σ, n::Int64)::Float64
    (x - μ) / (σ / sqrt(n))
end

function sampling_distribution(statistic::Function, d::Distribution, n::Int, r::Int)::Vector{Float64}
    Random.seed!(0)
    sample_statistics = zeros(r)
    sample = zeros(n)

    # Sampling r times and calculating the statistic
    @inbounds for i in 1:r
        rand!(d, sample)
        sample_statistics[i] = statistic(sample)::Float64
    end

    sample_statistics
end
```

This function creates a sampling distribution, using the given distribution and its parameters. It takes samples of size `n` and calculates each sample's `statistic`. It does this \`r\` times to create a sampling distribution and mitigate any concerns of natural sampling variability. It returns this sampling distribution for further analysis.

```{julia Single distribution analysis}
#| output: false
function analysis(statistic, d::Distribution, n::Int, r::Int, μ::Real, σ::Real, sample_statistics=sampling_distribution(statistic, d, n, r))::Tuple{Float64,Float64,Float64,Float64}
    skewness = StatsBase.skewness(sample_statistics)
    kurtosis = StatsBase.kurtosis(sample_statistics)

    z_scores = standardize.(sample_statistics, μ, σ, n)

    upper = sum(z_scores .>= 1.96) / r
    lower = sum(z_scores .<= -1.96) / r

    (upper, lower, skewness, kurtosis)
end
```

This function then finds the upper and lower tails of this sampling distribution under the assumption that it is normally distributed by looking at z-scores more extreme than $\pm$ 1.96. The function returns the tail weights along with the skewness and kurtosis of the sampling distribution.

```{julia Analyzing multiple distributions}
#| output: false
function analyze_distributions(statistic, r::Int64, sample_sizes::Vector{Int64}, distributions)::DataFrame
    println("Analyzing distributions with $(r) repetitions")
    # Some setup
    results = DataFrame(
        "Distribution" => String[],
        "Skewness" => Float64[],
        "Sample Size" => Int64[],
        "Upper Tail" => Float64[],
        "Lower Tail" => Float64[],
        "Sampling Skewness" => Float64[],
        "Sampling Kurtosis" => Float64[],
        "Population Mean" => Float64[],
        "Population SD" => Float64[]
    )

    # Analyzing each distribution
    @inbounds for d::Distribution in distributions
        println(string(d))

        # Getting population parameters
        μ = mean(d)
        σ = std(d)
        skewness = StatsBase.skewness(d)

        # Analyzing each sample size
        u = Threads.SpinLock() # lock to avoid data races
        @inbounds Threads.@threads for n in sample_sizes
            upper, lower, sample_skewness, sample_kurtosis = analysis(statistic, d, n, r, μ, σ)
            Threads.lock(u) do
                push!(results, (string(d), skewness, n, upper, lower, sample_skewness, sample_kurtosis, μ, σ))
            end
        end

    end

    sort!(results, [:Distribution, :"Sample Size"])
end
```

```{julia Generate data}
#| output: false
function main(r)
    sample_sizes = [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 250, 300, 400, 500]
    distributions = [
        Gamma(16),
        LogNormal(0, 0.25),
        Gamma(4),
        Gamma(2),
        LogNormal(0, 0.5),
        Gamma(1),
        Exponential(),
        Gamma(0.64),
        LogNormal(0, 0.75)
    ]
    # Compile
    analyze_distributions(mean, 1, sample_sizes, distributions)

    # Warning: this code will take a very long time to run if used with a large r. We used r = 10_000_000
    results::DataFrame = analyze_distributions(mean, r, sample_sizes, distributions)

    CSV.write("means.csv", results)
end
main() # remove this if you want to render the document but already have data
```

We used r = 10,000,000 repetitions to create our sampling distributions of means (means.csv). Keep in mind that, while Julia is fast, this is a non-trivial task and will take some time. It is highly recommended to run the code in a Julia REPL instead of this notebook.

## Analyzing the Data

```{r setup}
library(tidyverse)
library(flextable)

df <- read_csv("means.csv") |>
  group_by(Distribution) |>
  mutate(Distribution = str_replace(Distribution, "\\{.*\\}", " ")) |>
  filter(
    `Lower Tail` >= 0.02 & `Lower Tail` <= 0.03,
    `Upper Tail` >= 0.02 & `Upper Tail` <= 0.03
  ) |>
  filter(`Sample Size` == min(`Sample Size`)) |> # get the smallest sample size for each distribution
  select(Distribution, Skewness, `Sampling Skewness`, `Sample Size`) |>
  arrange(Skewness, Distribution)

ft <- flextable(df) |>
  colformat_double(j = c("Skewness", "Sampling Skewness"), digits = 3) |>
  font(fontname = "Trebuchet MS") |>
  autofit()

save_as_image(ft, path = "Poster//table.png", res = 2000)
ft
```

Now that we have the data, we may proceed with our analysis. We judged normality by looking at tailed-ness; we treated a distribution as normal if both of its tails were within 20% of 0.025 as that is what we would expect from a Normal distribution.

```{r Fitting the model}
model <- lm(Skewness ~ sqrt(`Sample Size`), df)
df |>
  ggplot(aes(x = sqrt(`Sample Size`), y = Skewness, label = Distribution)) +
  geom_abline(slope = coef(model)[2], intercept = coef(model)[1], color = "blue", linetype = "dashed", linewidth = 1.5) +
  geom_line(linewidth = 1.5) +
  geom_point(size = 3) +
  ggrepel::geom_label_repel(seed = 0, nudge_x = 1, size = 5) +
  labs(
    title = "Linear Relationship between Skewness and Empirical Minimum Square Root Sample Size",
    x = "Square Root of Sample Size",
    y = "Skewness"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 23),
    axis.title = element_text(size = 17),
    axis.text = element_text(size = 12)
  )

ggsave("Poster//Skew_Sample_Size.png", width = 15, height = 8.5, dpi = 1000)

summary(model)
```

We ran a linear regression to determine that if $n\geq36*skewness^2$ the sampling distribution of the means will be approximately normal as prior defined. We also plot the relationship between skewness and empirical sampling size that we found.

## Generating Some Graphs

This section is dedicated to creating data and graphs for the poster.

```{julia Generating Exponential data for graphing}
function graphing()
    d = Exponential()
    μ = mean(d)
    σ = std(d)
    n = 30

    exponential30 = sampling_distribution(mean, d, n, 10_000_000)
    exponential30std = standardize.(exponential30, μ, σ, n)

    n = 150
    exponential150 = sampling_distribution(mean, d, n, 10_000_000)
    exponential150std = standardize.(exponential150, μ, σ, n)

    graphing = DataFrame(
        "Exponential" => exponential30,
        "Exponential Z-Scores" => exponential30std,
        "Exponential 150" => exponential150,
        "Exponential 150 Z-Scores" => exponential150std
    )

    # Warning: this produces a large file which is why you will not find graphing.csv in the repository
    CSV.write("graphing.csv", graphing)
end

graphing()
```

We create the data used to graph the exponential sampling distributions

```{r Graphing sampling distributions}
#| message: false
graphing <- read_csv("graphing.csv") |>
  select("Exponential 30 Z-Scores", "Exponential 150 Z-Scores")

# Create exponential population plot
x <- seq(0, 5, length.out = 100)
y <- dexp(x, rate = 1)
sub <- ggplot() +
  geom_line(aes(x, y)) +
  labs(
    title = "Exponential Population with Rate = 1"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(size = 12),
    axis.text = element_blank(),
    axis.title = element_blank(),
    axis.ticks = element_blank()
  )

for (col_name in colnames(graphing)) {
  sample_size <- str_extract(col_name, "\\d+")

  upper <- sum(graphing[[col_name]] >= 1.96) / length(graphing[[col_name]])
  lower <- sum(graphing[[col_name]] <= -1.96) / length(graphing[[col_name]])

  main <- ggplot(graphing, aes(x = .data[[col_name]])) +
    geom_histogram(bins = 100, aes(y = after_stat(density))) +
    stat_function(
      fun = dnorm,
      args = list(mean = mean(graphing[[col_name]]), sd = sd(graphing[[col_name]])),
      color = "blue",
      linewidth = 1.25
    ) +
    geom_vline(xintercept = 1.96, linetype = "dashed", color = "blue") +
    annotate("text",
      x = 2.5,
      y = 0.1,
      label = "1.96 SDs",
      color = "blue",
      size = 5
    ) +
    annotate("text",
      x = -2.5,
      y = 0.1,
      label = "-1.96 SDs",
      color = "blue",
      size = 5
    ) +
    annotate("text",
      x = 3,
      y = 0.05,
      label = round(upper, 3),
      color = "black",
      size = 5
    ) +
    annotate("text",
      x = -3,
      y = 0.05,
      label = round(lower, 3),
      color = "black",
      size = 5
    ) +
    geom_vline(xintercept = -1.96, linetype = "dashed", color = "blue") +
    labs(
      title = paste("Sampling Distribution of Standardized Means for n =", sample_size),
      x = "Z Score",
      y = "Frequency"
    ) +
    theme_bw() +
    theme(
      plot.title = element_text(size = 20),
      axis.title = element_text(size = 17),
      axis.text = element_text(size = 12)
    )

  combined <- main + patchwork::inset_element(sub, 0.6, 0.6, 1, 1)

  ggsave(paste0("Poster//", str_replace(str_sub(col_name,1,-10)," ", "_"), ".png"), plot = combined, width = 12, height = 6.75, dpi = 200)
}
```

We create two sampling distributions of the Exponential distribution, which has a skewness of 2, to show how the distribution converges to a Normal distribution as sample size increases. We only look at n = 30 and n = 150 to compare the old guideline with the new one.

```{r Graphing tails}
read_csv("means.csv") |>
  mutate(
    Distribution = paste(str_replace(Distribution, "\\{.*\\}", " "), round(Skewness, 2)),
    Distribution = factor(Distribution, levels = unique(Distribution[order(-Skewness)]))
  ) |>
  arrange(Skewness) |>
  ggplot(aes(x = `Sample Size`, color = Distribution)) +
  geom_rect(
    aes(xmin = 0, xmax = Inf, ymin = 0.02, ymax = 0.03),
    fill = "grey",
    linewidth = 0
  ) +
  geom_hline(yintercept = 0.025, linetype = "dashed", linewidth = 1) +
  geom_line(aes(y = `Upper Tail`), linewidth = 1) +
  geom_line(aes(y = `Lower Tail`), linewidth = 1) +
  geom_vline(xintercept = 30, linetype = "dashed", linewidth = 0.75) +
  annotate("text", x = 40, y = 0.04, label = "n = 30", hjust = 0, size = 5, color = "black") +
  labs(
    title = "Upper and Lower Tail Weights of Sampling Distributions",
    x = "Sample Size",
    y = "Tail Weight"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 23),
    axis.title = element_text(size = 17),
    axis.text = element_text(size = 12)
  )


ggsave("Poster//Tail_Weights.png", width = 12, height = 6.75, dpi = 1000)
```

The convergence rate of a sampling distribution, as shown by the Berry-Essen theorem, is related to the third absolute normalized moment. Skewness directly affects the convergence rate as our skewness shows, and this graph shows the change in tailedness of skewed distributions as sample size changes. The highlighted area is what used as a threshold for normality–both tails being within 20% of 0.025.